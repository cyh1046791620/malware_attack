import os
import random

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import torch
from sklearn.metrics import auc, confusion_matrix, roc_curve
from torch import optim
from torch.nn.functional import sigmoid
from tqdm.auto import tqdm
import time

def set_seed(seed):
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True


def count_params(model, trainable_only=True):
    if trainable_only:
        return sum(p.numel() for p in model.parameters() if p.requires_grad)
    return sum(p.numel() for p in model.parameters())


def set_plt_style():
    plt.rcParams.update(
        {"text.usetex": True, "font.family": "serif", "font.serif": ["cm"],}
    )


def plot_confusion_matrix(model, test_loader, save_title, device, normalize="all"):
    y_true, y_pred = predict(model, test_loader, device)
    #conf_mat = confusion_matrix(y_true, y_pred, normalize=normalize)
    conf_mat = confusion_matrix(y_true, y_pred)
    axis_labels = ("Benign", "Malware")
    df = pd.DataFrame(conf_mat, index=axis_labels, columns=axis_labels)
    plot = sns.heatmap(df, annot=True, cmap="Blues")
    plot.figure.savefig(os.path.join("imgs", f"{save_title}_conf_mat.png"), dpi=300)
    plt.close(plot.figure)


def plot_roc_curve(models, test_loader, save_title, device):
    fig, ax = plt.subplots()
    ax.grid(linestyle="--")
    ax.set_xlabel("False Positive Rate")
    ax.set_ylabel("True Positive Rate")
    if isinstance(models, dict):
        for label, model in models.items():
            fpr, tpr, auc_score = _rates_auc(model, test_loader, device)
            ax.plot(fpr, tpr, label=f"{label} ({auc_score:.2f})")
    else:
        fpr, tpr, auc_score = _rates_auc(models, test_loader, device)
        ax.plot(fp, tpr, label=f"{save_title} ({auc_score:.2f})")
    ax.plot([0, 1], [0, 1], linestyle="--", label="Chance (0.5)")
    ax.legend(loc="best")
    fig.savefig(os.path.join("imgs", f"{save_title}_roc.png"), dpi=300)
    plt.close(fig)


def _rates_auc(model, test_loader, device):
    y_true, y_pred = predict(model, test_loader, device, apply_sigmoid=True)
    fpr, tpr, _ = metrics.roc_curve(y_true, y_pred)
    auc_score = auc(fpr, tpr)
    return fpr, tpr, auc_score


@torch.no_grad()
def predict(model, data_loader, device, apply_sigmoid=False, to_numpy=True):
    model.eval()
    y_true = []
    y_pred = []
    for inputs, labels in tqdm(data_loader, leave=False):
        inputs = inputs.to(device)
        outputs = model(inputs)
        # print(outputs)
        # exit()
        y_true.append(labels)
        y_pred.append(outputs)
    # print("-"*100)
    # print(torch.cat(y_true))
    # print(torch.cat(y_true).int())
    # print(type(torch.cat(y_true)))

    y_true = torch.cat(y_true).int()

    if apply_sigmoid:
        y_pred = sigmoid(torch.cat(y_pred))
    else:
        y_pred = (torch.cat(y_pred) > 0).int()
    if to_numpy:
        y_true = y_true.cpu().numpy()
        y_pred = y_pred.cpu().numpy()
    assert y_true.shape == y_pred.shape
    model.train()
    return y_true, y_pred


def get_accuracy(model, data_loader, device):
    # device="cpu"
    y_true, y_pred = predict(model, data_loader, device, to_numpy=False)
    # print(y_true)
    # print(y_pred)
    # exit()
    # return 100 * (y_true.cuda() == y_pred.cuda()).float().mean().item()
    return 100 * (y_true == y_pred).float().mean().item()


def plot_train_history(train_loss_history, val_loss_history, save_title):
    fig, ax = plt.subplots()
    time_ = range(len(train_loss_history))
    ax.set_xlabel("Epochs")
    ax.set_ylabel("BCE Loss")
    ax.grid(linestyle="--")
    ax.plot(time_, train_loss_history, color="blue", label="train loss")
    ax.plot(time_, val_loss_history, color="red", label="val loss")
    ax.legend(loc="best")
    fig.savefig(os.path.join("figures", f"{save_title}_train_history.png"), dpi=300)
    plt.close(fig)


def read_into_buffer(filename):
    buf = bytearray(os.path.getsize(filename))
    with open(filename, 'rb') as f:
        f.readinto(buf)
    f.close()
    return list(buf)


def get_test_acc():
    try:
        checkpoint = torch.load('./Detect_checkpoints/malconv_plus_500000_50.pt', map_location=lambda storage, loc: storage)
    except:
        checkpoint = torch.load('./Detect_checkpoints/malconv_plus_500000_50.pt')

    model.load_state_dict(checkpoint['model'])
    print(get_accuracy(model, test_loader, 'cpu'))


def get_test_acc1(model,test_loader):
    # model.load_state_dict(checkpoint['model'])
    device = torch.device("cuda:0" if torch.cuda.is_available else "cpu")
    return get_accuracy(model, test_loader, device)

def train(
    model,
    train_loader,
    val_loader,
    test_loader,
    device,
    save_title,
    l_epoch=0,
    lr=0.001,
    patience=3,
    num_epochs=50,
    verbose=True,
    optimizer="null",
):
    train_loss_history = []
    val_loss_history = []
    criterion = torch.nn.BCEWithLogitsLoss()
    if optimizer=="null":
        optimizer = optim.Adam(model.parameters(), lr=lr)
    #早停法，防止过拟合
    monitor = EarlyStopMonitor(patience)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, factor=0.5, patience=patience
    )
    for epoch in range(1, num_epochs + 1):
        model.train()
        train_loss = run_epoch(model, train_loader, device, criterion, optimizer)
        train_loss_history.append(train_loss)
        model.eval()
        with torch.no_grad():
            val_loss = run_epoch(model, val_loader, device, criterion)
        val_loss_history.append(val_loss)
        if verbose:
            tqdm.write(
                f"Epoch [{epoch+l_epoch}/{num_epochs+l_epoch}], "
                f"Train Loss: {train_loss:.4f}, "
                f"Val Loss: {val_loss:.4f}"
            )
        scheduler.step(val_loss)

        print("epoch:"+str(epoch+l_epoch))


        if epoch % 5 == 0:
            print("save pt")

            state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch+l_epoch}
            torch.save(
                state, os.path.join("../Detect_checkpoints", f"{save_title+str(epoch)}.pt"),
            )

    print('over')



def run_epoch(model, data_loader, device, criterion, optimizer=None):
    total_loss = 0
    for inputs, labels in tqdm(data_loader, leave=False):
        # print("inputs:")
        # print(inputs)
        inputs = inputs.to(device)
        # print("inputs:")
        # print(inputs)
        # exit()
        # print(len(inputs[1]))

        labels = labels.to(device)
        # print("labels:")
        # print(labels)

        outputs = model(inputs)
        # print("outputs:")
        # print(outputs)
        # print(torch.sigmoid(outputs))
        # exit()
        loss = criterion(outputs, labels)
        if optimizer:
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        total_loss += loss.item()
    return total_loss / len(data_loader)


class EarlyStopMonitor:
    def __init__(self, patience, mode="min"):
        assert mode in {"min", "max"}, "`mode` must be one of 'min' or 'max'"
        self.log = []
        self.mode = mode
        self.count = 0
        self.patience = patience

    def step(self, metric):
        if not self.log:
            self.log.append(metric)
            return False
        flag = metric > self.log[-1]
        if flag == (self.mode == "min"):
            self.count += 1
        else:
            self.count = 0
        self.log.append(metric)
        return self.count > self.patience

